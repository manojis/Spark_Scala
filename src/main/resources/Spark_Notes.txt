port forwarding Hortonworks:
https://hortonworks.com/tutorial/hortonworks-sandbox-guide/section/3/
https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.1.0/administration/content/reference.html
https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.1.0/administration/content/yarn-ports.html

Spark Best Practices
====================
https://umbertogriffo.gitbooks.io/apache-spark-best-practices-and-tuning/content/

RDD Programming Guide
====================
https://spark.apache.org/docs/latest/rdd-programming-guide.html

curl -L -o spmohst.txt "https://drive.google.com/uc?export=download&id=0ByJLBTmJojjzbVhvSnQwNlhXUWs"
C:\Users\manoj_nair\AppData\Local\Packages\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\LocalState\rootfs\home\manoj_nair\hadoop\apache-hive-3.1.1-bin\conf
hive --service metastore &
hive --service hiveserver2 &

create table stocks (date_ String, Ticker String, Open Double, High Double, Low Double, Close Double, Volume_for_the_day int) row format delimited fields terminated by ',';

select date_, ticker, close,lag(close, 1) over(partition by ticker) as yesterday_price from stocks;
select date_, ticker, close,case(lead(close,1) over(partition by ticker)-close) > 0 when true then "higher" when false then "lesser" end as Changes from stocks;
select ticker, first_value(high) over(partition by ticker) as first_high from stocks
select ticker, MAX(high) over(partition by ticker) as first_high from stocks group by ticker;

beeline -n manoj_nair -u jdbc:hive2://localhost:10000
beeline -n mohitha -u jdbc:hive2://localhost:10000

create table player_data_partitioned(user_id Int,video_id Int, hour String) PARTITIONED BY(video_id Int) row format delimited fields terminated by ',' tblproperties("skip.header.line.count"="1");
load data local inpath '/home/manoj_nair/player_data.txt' into table player_data_partitioned;

select distinct(video_id),hour, count(video_id) over(partition by video_id) as total from player_data where hour = '2019062419' order by total desc limit 1;

CREATE TABLE temps_orc_partition_date
(statecode STRING, state STRING, county STRING, dateoflastchange STRING)
PARTITIONED BY (datelocal STRING)
STORED AS ORC

hadoop fs -chmod -R 777 /user/hive
hadoop fs -chmod 777 /tmp

MYSQL Restart
===============
You should really use the Sys-V init scripts located in /etc/init.d.

Start:
sudo /etc/init.d/mysql start

Stop:
sudo /etc/init.d/mysql stop
Restart / reload configs:

sudo /etc/init.d/mysql restart

Check run status:
sudo /etc/init.d/mysql status

docker run --hostname=quickstart.cloudera --privileged=true -t -i -v /Users/sohamadwani/Documents/yourDirectory:/src --publish-all=true -p 8888 cloudera/quickstart /usr/bin/docker-quickstart

A container is an instance of the sandbox image. you must stop container dependencies before removing it.
docker stop sandbox-hdp
docker stop sandbox-proxy
docker rm sandbox-hdp
docker rm sandbox-proxy

Hortonworks Spark:
scp -P 2222 spark_scala_2.11-0.1.jar root@sandbox-hdp.hortonworks.com:/root
ssh root@sandbox-hdp.hortonworks.com -p 2222 -> WA3002g4
for creating the jar file
========================
sbt package


spark-submit --class WordCount --master local ./hello_scala_2.11-0.1.jar

https://courses.epam.com/courses/course-v1:EPAM+SAS+S1/courseware/6ae89a13f10b43bd84d56e6e7c7f0bc0/91af1136154a48cf9e43a7e02c7648e2/1
https://epam.sharepoint.com/sites/EPAMGCPCertificationMinskSeptember
https://learn.epam.com/detailsPage?id=d0d270d7-4ab5-4f55-87d9-4cae4cba02b1&source=TRAINING
https://learn.epam.com/detailsPage?id=7f2128cb-081d-4fc0-9b18-432b762ef119&source=TRAINING

AirportsUpperCaseProblem